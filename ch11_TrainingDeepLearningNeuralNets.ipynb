{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 11: Training Deep Learning Neural Nets\n",
    "-----\n",
    "-----\n",
    "\n",
    "Difficulties and Problems, using what we saw in ch10:\n",
    "- Vanishing gradient, exploding gradients\n",
    "- slow to train\n",
    "- risk of overfitting when a model number of parameters is very large\n",
    "\n",
    "## Vanishing/Exploding Gradient Problem\n",
    "-----\n",
    "\n",
    "Gradients get smaller and smaller as algorithm progresses down to lower layers, resulting in unchanged weights in those layers, so it never converges to good solution.\n",
    "\n",
    "The opposite can happen gradients grow larger, causing the algorithm to diverge,\n",
    "\n",
    "The problem with vanishing gradients was found to be linked to the use of the sigmoid activation function and initializing the weight with a random values form a normal distribution with mean of 0 and standard deviation of 1.\n",
    "- variance of output much greater than that of the inputs layers.\n",
    "- going forward in the network, increases the variance at each layer causing the sigmoid to saturate(0 and 1)\n",
    "- when staturation happens, the gradient approaches 0\n",
    "\n",
    "#### Xavier and He Initialization\n",
    "Need variance of input to be equal to output layers, and gradients must have equal variance before and after flowing through a layer in reverse direction.\n",
    "\n",
    "Weight initialized with:\n",
    "- Normal Distribution: mean of 0 and standard deviation $\\sigma = \\sqrt{\\frac{2} {n_{inputs} + n_{outputs}}}$\n",
    "- or Uniform Distribution: between -r and +r with $r = \\sqrt{\\frac{6} {n_{inputs} + n_{outputs}}}$\n",
    "\n",
    "using Xavier's strategy can speed up training. There are different strategies for different activation functions see page.278\n",
    "\n",
    "#### Nonsaturating Activation Functions\n",
    "Using ReLU in deep nets preform better, but have the probelm of `dying ReLU`: in traing some of the neurons die, the only output zeros.\n",
    "\n",
    "Using leaky ReLU can solve this.\n",
    "\n",
    "But using an `exponential linear unit`(ELU) seems to out-preform all ReLU varients.([2015 Paper](http://goo.gl/Sdl2P7))\n",
    "\n",
    "$$ELU_{\\alpha}(z) = \\[ \\left \\{ \\begin{tabular}{cc} \\alpha( exp(x) -1 ) & if z \\textless 0 \\\\z & if z \\geq 0 \\end{tabular} \\]$$\n",
    "http://quicklatex.com/cache3/e8/ql_2e08af9d00f36490ed605dc0f63200e8_l3.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Common imports\n",
    "import numpy as np\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
    "\n",
    "z = np.linspace(-5, 5, 200)\n",
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main drawback, slower to compute than ReLU, but faster to train so it compensates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# leaky relu\n",
    "\n",
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Normalization\n",
    "\n",
    "Addign operation in the model just before the activation function of each layer, simply zero-centering and normalizing the inputs, then scaling and shifting the result using two new parameter per layers.\n",
    "\n",
    "- achives same accuracy using less training steps\n",
    "- act like a regularizer\n",
    "- speeds up training\n",
    "- less sensitive to weight initilization\n",
    "- vanishing gradient problem reduced\n",
    "- adds complexity to the model\n",
    "\n",
    "##### Implementing Batch Normalization with Tensorflow\n",
    "function is provided `batch_normalization()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "###############\n",
    "# To avoid repeating the same parameters over and over again, we can use Python's partial() function:\n",
    "###############\n",
    "\n",
    "from functools import partial\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a net with ELU and batch normalization\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    hidden3 = my_dense_layer(bn2, 60, name=\"hidden3\")\n",
    "    bn3 = tf.nn.elu(my_batch_norm_layer(hidden3))\n",
    "    hidden4 = my_dense_layer(bn3, 30, name=\"hidden4\")\n",
    "    bn4 = tf.nn.elu(my_batch_norm_layer(hidden4))\n",
    "    logits_before_bn = my_dense_layer(bn4, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Validation accuracy: 0.9354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Validation accuracy: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Validation accuracy: 0.9524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Validation accuracy: 0.9568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Validation accuracy: 0.9598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Validation accuracy: 0.9652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Validation accuracy: 0.9664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Validation accuracy: 0.9694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.9686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Validation accuracy: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Validation accuracy: 0.9708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Validation accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Validation accuracy: 0.9722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Validation accuracy: 0.9728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Validation accuracy: 0.9736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Validation accuracy: 0.9736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Validation accuracy: 0.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Validation accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Validation accuracy: 0.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Validation accuracy: 0.9768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Validation accuracy: 0.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Validation accuracy: 0.9746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Validation accuracy: 0.9772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Validation accuracy: 0.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Validation accuracy: 0.9764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Validation accuracy: 0.977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Validation accuracy: 0.9774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Validation accuracy: 0.9766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Validation accuracy: 0.978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Validation accuracy: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Validation accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Validation accuracy: 0.979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 Validation accuracy: 0.9796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Validation accuracy: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Validation accuracy: 0.9782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 Validation accuracy: 0.9776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Validation accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Validation accuracy: 0.9786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Validation accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Validation accuracy: 0.9794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 Validation accuracy: 0.981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Validation accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Validation accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Validation accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 Validation accuracy: 0.981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Validation accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 Validation accuracy: 0.9802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Validation accuracy: 0.9796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 Validation accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Validation accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 Validation accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Validation accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 Validation accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 Validation accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 Validation accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 Validation accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 Validation accuracy: 0.9802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Validation accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 Validation accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 Validation accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 Validation accuracy: 0.9816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 Validation accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Validation accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 Validation accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Validation accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 Validation accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 Validation accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Validation accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 Validation accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 Validation accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 Validation accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 Validation accuracy: 0.9824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Validation accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 Validation accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 Validation accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Validation accuracy: 0.9816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 Validation accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Validation accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 Validation accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 Validation accuracy: 0.9824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 Validation accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 Validation accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 Validation accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 Validation accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 Validation accuracy: 0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 Validation accuracy: 0.984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 Validation accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 Validation accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 Validation accuracy: 0.9824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 Validation accuracy: 0.9824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 Validation accuracy: 0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 Validation accuracy: 0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 Validation accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 Validation accuracy: 0.9824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 Validation accuracy: 0.9824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 Validation accuracy: 0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185 Validation accuracy: 0.984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 Validation accuracy: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191 Validation accuracy: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 Validation accuracy: 0.9824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 Validation accuracy: 0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 Validation accuracy: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 Validation accuracy: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 Validation accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "batch_size = 200\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"tmp_models/ch11_batchNorm_ELU.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Clipping\n",
    "\n",
    "Simply clip gradients during backprop, hyperparameter threshold can be tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers\n",
    "-----\n",
    "\n",
    "Using the lower layers of an existing network that solved a similar problem , speeds up training and requires less data. (transfer learning)\n",
    "\n",
    "#### Reusing a TensorFlow Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):                                            # not shown in the book\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): # not shown\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})        # not shown\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})     # not shown\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)                   # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reusing Models from Other Frameworks\n",
    "\n",
    "#### Freezing the lower Layers\n",
    "Likely that lower layers in first DNN have learned low level features that will be useful across both image classification taks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                   scope=\"hidden[34]|outputs\")\n",
    "training_op = optimizer.minimize(loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching the Frozen Layers\n",
    "\n",
    "#### Tweaking, Dropping, or Replacing the Upper Layers\n",
    "Output layer should be replaced. upper hidden layer are likely not to be useful.\n",
    "\n",
    "#### Model Zoos\n",
    "search for tensorflow models which have been train one similar tasks that you are trying to achieve.\n",
    "\n",
    "#### Unsupervised Pretraining\n",
    "using RBM or autoencoders\n",
    "\n",
    "#### Pretraining on an Auxiliary Task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster Optimizers\n",
    "-----\n",
    "\n",
    "- Momentum Optimization\n",
    "- Nesterov accelerated gradient\n",
    "- AdaGrad\n",
    "- RMSProp\n",
    "- Adam Optimization(always use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum Optimization\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9)\n",
    "\n",
    "# Nesterov accelerated gradient\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9, use_nesterov=True)\n",
    "\n",
    "# AdaGrad\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# RMSProp\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n",
    "                                      momentum=0.9, decay=0.9, epsilon=1e-10)\n",
    "\n",
    "# Adam Optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling\n",
    "\n",
    "- predetermined piecewise constant learning rate: start at a number and after x epochs change number to small value\n",
    "- performance scheduling: measures the validation error every N steps and reduces learning rate by a factor when learning rate stops dropping\n",
    "- exponential scheduling: set learning rate to a function of the iteration number\n",
    "- power scheduling: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
    "                                               decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not needed for AdaGrad, RMSProp and Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding Overfitting Through Regularization\n",
    "-----\n",
    "- early stopping\n",
    "- l1 and l2 reg\n",
    "- dropout\n",
    "- max-norm reg\n",
    "- data augmentation\n",
    "\n",
    "#### Early Stopping\n",
    "stop training early when performance on validation set starts droping\n",
    "\n",
    "#### L1 and L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[...] # construct nural net\n",
    "base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "loss = tf.add(base_loss, scale * reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or \n",
    "\n",
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None,\n",
    "                            name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):                                     \n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(  \n",
    "        labels=y, logits=logits)                                \n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")   \n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout\n",
    "every neuron excluding the output has a probability p of being temporarily \"dropped out\" meaning it is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "dropout_rate = 0.5  # == 1 - keep_prob\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Validation accuracy: 0.9328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Validation accuracy: 0.9364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Validation accuracy: 0.9414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Validation accuracy: 0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Validation accuracy: 0.9294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Validation accuracy: 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Validation accuracy: 0.9428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Validation accuracy: 0.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 Validation accuracy: 0.9424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Validation accuracy: 0.9422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 Validation accuracy: 0.9418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 Validation accuracy: 0.947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Validation accuracy: 0.9422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Validation accuracy: 0.9374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 Validation accuracy: 0.9432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Validation accuracy: 0.9354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Validation accuracy: 0.9382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Validation accuracy: 0.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Validation accuracy: 0.9398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Validation accuracy: 0.9398\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        if((epoch + 1) % 5 == 0):\n",
    "            print(epoch + 1, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./ch11_dropout.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max-Norm Regularization\n",
    "\n",
    "constraints thw weights  of incoming connections such that $||w||_2 \\leq r$ , r is the max-norm hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## better\n",
    "\n",
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\",\n",
    "                         collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None # there is no regularization loss term\n",
    "    return max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Validation accuracy: 0.9706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Validation accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Validation accuracy: 0.9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Validation accuracy: 0.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Validation accuracy: 0.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Validation accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Validation accuracy: 0.9802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Validation accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Validation accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Validation accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Validation accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Validation accuracy: 0.9838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Validation accuracy: 0.9834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Validation accuracy: 0.9842\n"
     ]
    }
   ],
   "source": [
    "clip_all_weights = tf.get_collection(\"max_norm\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights)\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # not shown\n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)               # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"tmp_models/ch11_MAXNormReg.ckpt\")             # not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation\n",
    "generate new training instances using existing ones.\n",
    "for image data:\n",
    "- shift\n",
    "- rotate\n",
    "- resize\n",
    "- change contrast\n",
    "\n",
    "tensorflow has image manipulation APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "-----\n",
    "\n",
    "1. No\n",
    "2. yes it fine\n",
    "3. ELU:\n",
    "\t- can take negative, so average closer to 0, which help reduce the vanishing gradient problem\n",
    "\t- non zero derivative\n",
    "\t- smooth everywhere\n",
    "4. ELU good base, leaky ReLU is fast, ReLU is simple.\n",
    "5. it will oscillate a lot, since it momentum is so high\n",
    "6. l1 regularization, lots of weights to be zero\n",
    "7. slows down training but not inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
